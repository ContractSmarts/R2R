[app]
  # LLM used for internal operations, like deriving conversation names
  fast_llm = "azure/gpt-4.1-mini"
  # LLM used for user-facing output, like RAG replies
  quality_llm = "azure/gpt-4.1"
  # LLM used for processing visual inputs (same as main model)
  vlm = "azure/gpt-4.1"
  # LLM used for transcription
  audio_lm = "azure/whisper-1"
  # Research agent models (e.g., multi-step reasoning)
  reasoning_llm = "azure/o4-mini"
  planning_llm  = "azure/o4-mini"

[embedding]
  # Used for document vectorization
  provider = "litellm"
  base_model = "azure/text-embedding-3-small"
  base_dimension = 512
  #base_dimension = 1536 # default for text-embedding-3-small
  concurrent_request_limit = 256
  max_retries = 3
  initial_backoff = 1.0
  max_backoff = 64.0

[completion_embedding]
  # Used for embedding LLM completions (e.g., enriched summaries)
  provider = "litellm"
  base_model = "azure/text-embedding-3-small"
  base_dimension = 512
  concurrent_request_limit = 256

[ingestion]
  provider = "unstructured_local"
  strategy = "auto"                 # auto-select best parser per file type
  chunking_strategy = "by_title"    # keep chunks aligned with sections
  new_after_n_chars = 2048          # split chunks when title is far away
  max_characters = 4096             # upper limit for any single chunk (try 8192 for legal documents)
  combine_under_n_chars = 1024      # small chunks get merged
  overlap = 1024                    # soft overlap between adjacent chunks

document_summary_model = "azure/gpt-4.1-mini"
  # enable automatic extraction of entities and relations
  automatic_extraction = true

  [ingestion.extra_parsers]
    pdf = ["zerox", "ocr"]

  [ingestion.chunk_enrichment_settings]
    generation_config = { model = "azure/gpt-4.1-mini" }

# ------------------------------------------------------
# [orchestration] section: Hatchet settings
# ------------------------------------------------------
[orchestration]
  provider = "hatchet"
  grpc_host = "hatchet-engine"
  grpc_port = 7077
  use_tls = false
  tls_insecure = true
  
  ## 4 vCPU deployment
  kg_creation_concurrency_limit = 4 # 4-6
  ingestion_concurrency_limit = 4   # align with vCPU count
  kg_concurrency_limit = 4          # tune for knowledge graph if needed

### Orchestration Options:

# ## Original config (large-scale deployment)
# ## Azure F32s_v2, D32s_v5, E32s_v5
# ## 
# # kg_creation_concurrency_limit = 32 # ~32 vCPUs
# # ingestion_concurrency_limit = 4    # 4+ vCPUs
# # kg_concurrency_limit = 8           # 8+ vCPUs
# 
# ## 8 vCPU settings
# # kg_creation_concurrency_limit = 8-12
# # ingestion_concurrency_limit = 4-6
# # kg_concurrency_limit = 6-8
# 
# ## 4 vCPU settings
# # kg_creation_concurrency_limit = 4-6
# # ingestion_concurrency_limit = 3-4
# # kg_concurrency_limit = 4
# 
# ## 2 vCPU settings (E2s v6)
# # kg_creation_concurrency_limit = 2
# # ingestion_concurrency_limit = 2
# # kg_concurrency_limit = 2

# ------------------------------------------------------
# [file] section: File Storage (postgres or s3) 
#   see https://r2r-docs.sciphi.ai/self-hosting/configuration/file-storage
# ------------------------------------------------------
[file]
  provider = "postgres"

# ------------------------------------------------------
# [database] section: Enable for rate limiting & quotas
# ------------------------------------------------------
[database]
  default_collection_name = "Default"
  default_collection_description = "Your default collection."
  collection_summary_prompt = "collection_summary"

  [database.graph_creation_settings]
    graph_entity_description_prompt = "graph_entity_description"
    graph_extraction_prompt = "graph_extraction"
    entity_types = [] # if empty, all entities are extracted
    relation_types = [] # if empty, all relations are extracted
    automatic_deduplication = true # enable automatic deduplication of entities

  [database.graph_enrichment_settings]
    graph_communities_prompt = "graph_communities"

  [database.limits]
    # Per-R2R global rate limits
    global_per_min = 60           # number of requests per minute allowed
    monthly_limit = 10000         # total requests allowed per month

  [database.route_limits]
    "/v3/retrieval/search" = { route_per_min = 30, monthly_limit = 5000 }

#  # Optional: User-specific rate limiting (by user UUID)
#  [database.user_limits."47e53676-b478-5b3f-a409-234ca2164de5"]
#    global_per_min = 10
#    route_per_min = 5

# ------------------------------------------------------
# [auth] section: Optional; enable for login, access control
# ------------------------------------------------------
[auth]
  provider = "r2r"                        # Options: r2r, oidc (experimental)
  access_token_lifetime_in_minutes = 60
  refresh_token_lifetime_in_days = 7
  require_authentication = true          # Enforce login for all endpoints
  require_email_verification = false     # Turn on if you're sending emails
  default_admin_email = "david@contractsmarts.ai"
  default_admin_password = "contractsmartsAdminPwd"

## For OIDC (e.g., Auth0, Azure AD) â€” future option
#[auth.oidc]
#issuer_url = "https://login.microsoftonline.com/your-tenant-id/v2.0"
#client_id = "your-client-id"
#client_secret = "your-client-secret"
#redirect_uri = "https://your-app-url/callback"
