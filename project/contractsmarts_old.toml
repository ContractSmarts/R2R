[app]
# LLM used for internal operations, like deriving conversation names
fast_llm = "azure/gpt-4o-mini"

# LLM used for user-facing output, like RAG replies
quality_llm = "azure/gpt-4o"

# LLM used for ingesting visual inputs
vlm = "azure/gpt-4o"

# LLM used for transcription
audio_lm = "azure/whisper-1"

# Reasoning model, used for `research` agent
reasoning_llm = "azure/o3-mini"

# Planning model, used for `research` agent
planning_llm = "azure/o3-mini"

[embedding]
base_model = "azure/text-embedding-3-small"
# leave blank for default base_dimension
#base_dimension = 512

[completion_embedding]
base_model = "azure/text-embedding-3-small"

[ingestion]
provider = "unstructured_local"
strategy = "auto"
chunking_strategy = "by_title"
new_after_n_chars = 2_048
max_characters = 4_096
combine_under_n_chars = 1_024
overlap = 1_024
document_summary_model = "azure/gpt-4o-mini"
automatic_extraction = true # enable automatic extraction of entities and relations

  [ingestion.extra_parsers]
    pdf = ["zerox", "ocr"]

  [ingestion.chunk_enrichment_settings]
    generation_config = { model = "azure/gpt-4o-mini" }

[orchestration]
provider = "hatchet"
kg_creation_concurrency_limit = 32
ingestion_concurrency_limit = 4
kg_concurrency_limit = 8

## Database Limits (not required but adjustable)
## these values are unreasonably small but made this way to be testable

#[database]
#  [database.limits]
#  global_per_min = 10  # Small enough to test quickly
#  monthly_limit = 20  # Small enough to test in one run
#
#  [database.route_limits]
#  "/v3/retrieval/search" = { route_per_min = 5, monthly_limit = 10 }
#
#  [database.user_limits."47e53676-b478-5b3f-a409-234ca2164de5"]
#  global_per_min = 2
#  route_per_min = 1

## Optional auth section
##

#[auth]
#provider = "r2r"
#access_token_lifetime_in_minutes = 60
#refresh_token_lifetime_in_days = 7
#require_authentication = true
#require_email_verification = false
#default_admin_email = "admin@example.com"
#default_admin_password = "change_me_immediately"
